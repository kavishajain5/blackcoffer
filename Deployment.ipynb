{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPr/lfaIEbNTYCJLg4dbi6c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavishajain5/Ineuron-Internship-/blob/main/Deployment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "!pip install pickle"
      ],
      "metadata": {
        "id": "mLIe0JC6CDHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yi3O_X4UByaM"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import gradio as gr\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved models\n",
        "vectorizer = pickle.load(open('tfidf_vector.model', 'rb'))\n",
        "logistic_regression_model = pickle.load(open('logistic_regression.model', 'rb'))"
      ],
      "metadata": {
        "id": "yLXJteKMB2P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def chars(text):\n",
        "    return re.sub('[^A-Za-z0-9 ]+', '', text)\n",
        "\n",
        "def decontractions(phrase):\n",
        "    \"\"\"Decontracted takes text and converts contractions into their natural form.\"\"\"\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
        "    return phrase\n",
        "\n",
        "def stopwords(text):\n",
        "    text = text.split(' ')\n",
        "    output = [i for i in text if i not in stopwords]\n",
        "    return ' '.join(output)\n",
        "def stemming(text):\n",
        "    text = text.split(' ')\n",
        "    stem_text = [porter_stemmer.stem(word) for word in text]\n",
        "    return ' '.join(stem_text)\n",
        "def lemmatizer(text):\n",
        "    text = text.split(' ')\n",
        "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
        "    return ' '.join(lemm_text)\n",
        "\n",
        "def preprocessing(text_df):\n",
        "    text_df = text_df.apply(lambda x : chars(x))\n",
        "    text_df = text_df.apply(lambda x : x.lower())\n",
        "    text_df = text_df.apply(lambda x : decontractions(x))\n",
        "    text_df = text_df.apply(lambda x: remove_stopwords(x))\n",
        "    text_df = text_df.apply(lambda x: stemming(x))\n",
        "    text_df = text_df.apply(lambda x: lemmatizer(x))\n",
        "    return text_df\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "yGkH1hZNCuBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define prediction function\n",
        "def predict_category(text):\n",
        "    preprocessed_text = preprocess_text(text)\n",
        "    vectorized_text = vectorizer.transform([preprocessed_text])\n",
        "    prediction = logistic_regression_model.predict(vectorized_text)\n",
        "    return prediction[0]"
      ],
      "metadata": {
        "id": "CkhCZoFHDBOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Gradio interface\n",
        "iface = gr.Interface(fn=predict_category,\n",
        "                     inputs=gr.inputs.Textbox(lines=5, label=\"Enter News Text\"),\n",
        "                     outputs=\"text\",\n",
        "                     title=\"News Classification\",\n",
        "                     description=\"Enter text to classify it into one of the news categories.\")\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "FvEreZmpB5FL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}